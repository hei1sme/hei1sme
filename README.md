<div align="center">

<!-- Sleek Header -->
<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=12&height=150&section=header&text=Gia-Hung%20Nguyen%20Le&fontSize=40&fontColor=fff&animation=twinkling&fontAlignY=38" />

<h3>
  <img src="https://readme-typing-svg.demolab.com?font=Fira+Code&weight=500&size=24&duration=3000&pause=1000&color=667EEA&center=true&vCenter=true&width=600&lines=AI+Researcher+%F0%9F%94%AC;Building+Explainable+AI+Systems+%F0%9F%A7%A0;Founder+of+SpeedyLabX+%F0%9F%9A%80" alt="Typing SVG" />
</h3>

[![Portfolio](https://img.shields.io/badge/üåê_Portfolio-667eea?style=for-the-badge&logoColor=white)](https://hei-portfolio.vercel.app)
[![Scholar](https://img.shields.io/badge/üìö_Google_Scholar-4285F4?style=for-the-badge&logo=google-scholar&logoColor=white)](https://scholar.google.com/citations?user=iGODAQYAAAAJ)
[![LinkedIn](https://img.shields.io/badge/üíº_LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/le-nguyen-gia-hung)

<br/>

```diff
@@ Third-year AI Student @ FPT University | GPA: 8.62/10.0 @@
+ Published Researcher in Springer LNAI (Q2)
+ Founder of SpeedyLabX Research Group
! Seeking Research Internships & Collaboration Opportunities
```

</div>

<br/>

## üëã About Me

```yaml
focus: "Building transparent, interpretable AI systems"
specialization:
  - Explainable AI (SHAP, Attention Mechanisms)
  - Multimodal Learning (Audio-Text-Vision)
  - Time-Series Forecasting (Transformers)
  - Speech Processing (Low-Resource ASR)
```

I'm an AI researcher passionate about making machine learning models more interpretable and trustworthy. As founder of **SpeedyLabX**, I lead a team of 10 undergraduate researchers exploring cutting-edge problems in explainability, multimodal fusion, and speech systems.

<br/>

## üî¨ Featured Research

<div align="center">

<table>
<tr>
<td align="center" width="33%">
<img src="https://img.icons8.com/clouds/100/000000/air-quality.png" width="80"/>

### **SmokeNet**

**Air Quality Forecasting**

```python
metrics = {
  "MAE": 0.7470,
  "R¬≤": 0.9545,
  "improvement": "35.9% vs XGBoost"
}
```

Transformer-based system with SHAP explainability for public health warnings

`PyTorch` `Transformer` `SHAP` `XAI`

[![Paper](https://img.shields.io/badge/DOI-10.1007/978--981--95--4969--6__34-blue?style=flat-square&logo=doi)](https://doi.org/10.1007/978-981-95-4969-6_34)
[![Q2](https://img.shields.io/badge/Springer-LNAI_Q2-success?style=flat-square)](https://doi.org/10.1007/978-981-95-4969-6_34)

**AJCAI 2025** ‚Ä¢ *First Author*

</td>
<td align="center" width="33%">
<img src="https://img.icons8.com/clouds/100/000000/emotion.png" width="80"/>

### **MERR-GAT**

**Emotion Recognition**

```python
architecture = {
  "audio": "Wav2Vec2",
  "text": "RoBERTa",
  "fusion": "GATv2"
}
```

Graph-based multimodal fusion with intrinsic attention explainability

`Wav2Vec2` `RoBERTa` `GATv2` `XAI`

[![Status](https://img.shields.io/badge/Status-In_Progress-yellow?style=flat-square)](https://github.com/SpeedyLabX)
[![Code](https://img.shields.io/badge/GitHub-SpeedyLabX-181717?style=flat-square&logo=github)](https://github.com/SpeedyLabX)

**IEMOCAP ‚Ä¢ RAVDESS ‚Ä¢ MELD**

</td>
<td align="center" width="33%">
<img src="https://img.icons8.com/clouds/100/000000/microphone.png" width="80"/>

### **Vietnamese ASR**

**Speech Recognition**

```python
model = {
  "params": "5.4M",
  "data": "745 hours",
  "WER": "33.09%",
  "CER": "15.28%"
}
```

Parameter-efficient CNN-BiLSTM with CTC for Vietnamese speech

`CNN` `BiLSTM` `CTC` `ASR`

[![WER](https://img.shields.io/badge/WER-33.09%25-informational?style=flat-square)](https://github.com/SpeedyLabX)
[![CER](https://img.shields.io/badge/CER-15.28%25-informational?style=flat-square)](https://github.com/SpeedyLabX)

**Competitive vs Foundation Models**

</td>
</tr>
</table>

</div>

<br/>

## üìù Publications

```bibtex
@inproceedings{le2025smokenet,
  title     = {Proactive Air Quality Forecasting and Health Alert System for Melbourne},
  author    = {Gia-Hung Nguyen Le and others},
  booktitle = {AI 2025: Advances in Artificial Intelligence},
  series    = {Lecture Notes in Artificial Intelligence (LNAI)},
  publisher = {Springer Nature Singapore},
  year      = {2025},
  note      = {Q2 (SJR 2024)}
}
```

**[üìÑ Full Paper](https://doi.org/10.1007/978-981-95-4969-6_34)** ‚Ä¢ *First Author & Corresponding Author*

<br/>

## üéØ Research & Skills

<table>
<tr>
<td width="50%">

```yaml
research_focus:
  time_series:
    - Transformer architectures
    - Environmental prediction
    - Chronological cross-validation
    
  multimodal_learning:
    - Audio-text fusion
    - Graph Neural Networks
    - Conversational AI
    
  explainable_ai:
    - SHAP interpretability
    - Attention mechanisms
    - Integrated Gradients
    
  speech_processing:
    - End-to-end ASR
    - Low-resource languages
    - CTC optimization
```

</td>
<td width="50%">

```yaml
technical_stack:
  languages:
    - Python
    - SQL (PostgreSQL)
  
  frameworks:
    deep_learning: [PyTorch, TensorFlow, Keras]
    ml_tools: [Scikit-learn, Hugging Face, OpenCV]
    
  mlops:
    - Docker
    - Weights & Biases
    - Git
    - Linux
    - Streamlit
    
  data_science:
    - Pandas
    - NumPy
    - Matplotlib
```

</td>
</tr>
</table>

<br/>

## üõ†Ô∏è Tech Arsenal

<div align="center">

<table>
<tr>
<td align="center" width="25%">

**Languages**

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-4479A1?style=for-the-badge&logo=postgresql&logoColor=white)

</td>
<td align="center" width="25%">

**Deep Learning**

![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)

</td>
<td align="center" width="25%">

**ML Ecosystem**

![HuggingFace](https://img.shields.io/badge/HuggingFace-FFD21E?style=for-the-badge&logo=huggingface&logoColor=000)
![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)

</td>
<td align="center" width="25%">

**MLOps & Tools**

![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Weights & Biases](https://img.shields.io/badge/Weights_&_Biases-FFBE00?style=for-the-badge&logo=weightsandbiases&logoColor=black)

</td>
</tr>
</table>

</div>

<br/>

## üìä GitHub Activity

<div align="center">

<img src="https://github-readme-streak-stats.herokuapp.com/?user=hei1sme&theme=tokyonight&hide_border=true&border_radius=10&date_format=M%20j%5B%2C%20Y%5D" alt="GitHub Streak" height="180"/>
<img src="https://github-readme-stats.vercel.app/api?username=hei1sme&show_icons=true&theme=tokyonight&hide_border=true&border_radius=10&include_all_commits=true&count_private=true" alt="GitHub Stats" height="180"/>

<br/><br/>

<img src="https://github-readme-activity-graph.vercel.app/graph?username=hei1sme&theme=tokyo-night&hide_border=true&border_radius=10&area=true&custom_title=Contribution%20Graph" alt="Activity Graph" width="90%"/>

</div>

<br/>

## üèÜ Achievements & Leadership

<div align="center">

| üéØ Achievement | üìÖ Year | üîó Details |
|:---------------|:--------|:-----------|
| **Published in Springer LNAI** | 2025 | First-author paper at AJCAI (Q2) |
| **Founded SpeedyLabX** | 2024 | Research group of 10+ undergraduates |
| **Certificate of Merit** | 2024-25 | Honorable Student (Semesters 3, 4, 5) |
| **Vietnamese ASR Breakthrough** | 2025 | 33.09% WER on 745-hour corpus |
| **IBM Data Science Certifications** | 2024 | Professional Certificate track |

</div>

<br/>

## üë• SpeedyLabX Leadership

```typescript
const speedyLabX = {
  role: "Founder & Student Lead",
  established: 2025,
  team_size: "10+ undergraduate researchers",
  
  activities: [
    "Weekly technical workshops and paper reading groups",
    "End-to-end publication workflow management",
    "Mentoring on deep learning & research methodology",
    "Successfully guided first AJCAI-accepted paper"
  ],
  
  focus_areas: [
    "Explainable AI",
    "Multimodal Learning", 
    "Speech & NLP",
    "Time-Series Forecasting"
  ]
}
```

<br/>

---

<div align="center">

### üíº Open to Opportunities

```diff
! Actively seeking Research Internships & Collaborations in:
+ Explainable AI & Interpretable Machine Learning
+ Multimodal Learning (Audio-Visual-Text)
+ Speech & Natural Language Processing
+ Time-Series Forecasting & Graph Neural Networks
```

<br/>

### üì´ Let's Connect!

[![Email](https://img.shields.io/badge/Email-heiontheway@gmail.com-EA4335?style=for-the-badge&logo=gmail&logoColor=white)](mailto:heiontheway@gmail.com)
[![SpeedyLabX](https://img.shields.io/badge/SpeedyLabX-Research_Group-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/SpeedyLabX)
[![Portfolio](https://img.shields.io/badge/Portfolio-Technical_Writing-667eea?style=for-the-badge)](https://hei-portfolio.vercel.app)

<br/>

**Academic Profiles**

[![ORCID](https://img.shields.io/badge/ORCID-0009--0003--7120--8167-A6CE39?style=flat-square&logo=orcid&logoColor=white)](https://orcid.org/0009-0003-7120-8167)
[![Google Scholar](https://img.shields.io/badge/Scholar-iGODAQYAAAAJ-4285F4?style=flat-square&logo=google-scholar&logoColor=white)](https://scholar.google.com/citations?user=iGODAQYAAAAJ)
[![Scopus](https://img.shields.io/badge/Scopus-60219530700-E9711C?style=flat-square&logo=scopus&logoColor=white)](https://www.scopus.com/authid/detail.uri?authorId=60219530700)
[![Web of Science](https://img.shields.io/badge/ResearcherID-PCR--6096--2025-5856D6?style=flat-square)](https://www.webofscience.com/wos/author/record/PCR-6096-2025)

<br/>

![Profile Views](https://komarev.com/ghpvc/?username=hei1sme&color=667eea&style=for-the-badge&label=PROFILE+VIEWS)

<br/>

*FPT University ‚Ä¢ Ho Chi Minh City, Vietnam üáªüá≥*

</div>

<!-- Footer -->
<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=12&height=100&section=footer" />
